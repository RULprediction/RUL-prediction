{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the \"../data/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../data\"))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "233a981a029b7e030188616da57efb8459cf48d3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainset0 = pd.read_csv('../data/Dataset 002_train data without normalization.csv')\n",
    "testset0 = pd.read_csv('../data/Dataset 002_test data without normalization.csv')\n",
    "trainset1 = pd.read_csv('../data/Dataset 002_train data after normalization.csv')\n",
    "testset1 = pd.read_csv('../data/Dataset 002_test data after normalization.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcd25b4a157e90f4c84fee6a8eaadbed15495b56"
   },
   "source": [
    "# Display methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "caef94006b03b772bf402d6e93b8c42c689fda2c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "10413d43aa714d34debde4235595013468a9a3ab"
   },
   "source": [
    "This method is used to plot the prediction vs actual RULs for every unit (from startUnit to endUnit) the default number of columns is 4 and the default figure size is 15, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "352909d06052755610ed7a654b3109f40492365c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Display methods\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "def plotUnitLines(y_pred, startUnit, endUnit, ncols=4, title='', figsize=[15, 15]):\n",
    "    nunits = endUnit - startUnit + 1\n",
    "    nrows = math.ceil(nunits/ncols)\n",
    "    fig, axes=plt.subplots(nrows=nrows, ncols=ncols, clear=True, figsize=figsize)\n",
    "    for unit in range(startUnit, endUnit+1):\n",
    "        unitBooleanIndexes = testset0['unit']==unit;\n",
    "        unit_pred = list(map(lambda x: x[0], y_pred[unitBooleanIndexes]))\n",
    "        length = len(unit_pred)\n",
    "        #Get the rul for each unit based on its unit boolean index\n",
    "        y_rul = y_test0[unitBooleanIndexes].values\n",
    "        mse = mean_squared_error(y_rul, unit_pred)\n",
    "        x = range(len(unit_pred))\n",
    "        rowIndex = math.floor((unit-startUnit)/ncols)\n",
    "        colIndex = (unit-startUnit)%ncols;\n",
    "        ax = axes[rowIndex, colIndex]\n",
    "        ax.plot(x, unit_pred, label= 'predicted')\n",
    "        ax.plot(x, y_rul, label='actual')\n",
    "        ax.set_title('Unit'+str(unit) + ', MSE: '+str(mse))\n",
    "        ax.legend()\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c4e38460165efef847c8709b6d2b676d1bb383dd"
   },
   "source": [
    "This method is used to plot the history (the loss, mse) of the training after every epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "82090acb4019b9f715f29ffac3a202b8ea5e91d1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotLossHistory(model):\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f3146b976981da048b8aaabd063d1654c744a255"
   },
   "source": [
    "This method is used to plot the loss and also the validation loss (mse) after every epoch (this includes also the validation mse to help guiding the users about which model would be best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "84212d29359295333f94d4d43a1aeaabeb5b2ff5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotTrainHistory(model):\n",
    "    plt.plot(model.history['loss'])\n",
    "    plt.plot(model.history['val_loss'])\n",
    "    plt.title('Training history')\n",
    "    plt.ylabel('mse')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'validate'], loc='upper right')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b1d7705943c1d197bc2fa7253ebae4556c0e1267"
   },
   "source": [
    "# RBF\n",
    "This method implements the RBF layer for RBF Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91d5f1e83248cc5143b1ec5e754bc55cc0dc2d75",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#RBF adopted from: https://github.com/PetraVidnerova/rbf_keras\n",
    "import random \n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras.initializers import RandomUniform, Initializer, Orthogonal, Constant\n",
    "import numpy as np\n",
    "\n",
    "class InitCentersRandom(Initializer):\n",
    "    \"\"\" Initializer for initialization of centers of RBF network\n",
    "        as random samples from the given data set.\n",
    "    # Arguments\n",
    "        X: matrix, dataset to choose the centers from (random rows \n",
    "          are taken as centers)\n",
    "    \"\"\"\n",
    "    def __init__(self, X):\n",
    "        self.X = X \n",
    "\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        assert shape[1] == self.X.shape[1]\n",
    "        idx = np.random.randint(self.X.shape[0], size=shape[0])\n",
    "        return self.X[idx,:]\n",
    "\n",
    "        \n",
    "class RBFLayer(Layer):\n",
    "    \"\"\" Layer of Gaussian RBF units. \n",
    "    # Example\n",
    " \n",
    "    ```python\n",
    "        model = Sequential()\n",
    "        model.add(RBFLayer(10,\n",
    "                           initializer=InitCentersRandom(X), \n",
    "                           betas=1.0,\n",
    "                           input_shape=(1,)))\n",
    "        model.add(Dense(1))\n",
    "    ```\n",
    "    \n",
    "    # Arguments\n",
    "        output_dim: number of hidden units (i.e. number of outputs of the layer)\n",
    "        initializer: instance of initiliazer to initialize centers\n",
    "        betas: float, initial value for betas \n",
    "    \"\"\"\n",
    "    def __init__(self, output_dim, initializer=None, betas=1.0, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        self.init_betas = betas \n",
    "        if not initializer:\n",
    "            self.initializer = RandomUniform(0.0, 1.0)\n",
    "            #self.initializer = Orthogonal()\n",
    "        else:\n",
    "            self.initializer = initializer \n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \n",
    "        self.centers = self.add_weight(name='centers', \n",
    "                                       shape=(self.output_dim, input_shape[1]),\n",
    "                                       initializer=self.initializer,\n",
    "                                       trainable=True)\n",
    "        self.betas = self.add_weight(name='betas',\n",
    "                                     shape=(self.output_dim,),\n",
    "                                     initializer=Constant(value=self.init_betas),\n",
    "                                     #initializer='ones',\n",
    "                                     trainable=True)\n",
    "            \n",
    "        super(RBFLayer, self).build(input_shape)  \n",
    "\n",
    "    def call(self, x):\n",
    "\n",
    "        C = K.expand_dims(self.centers)\n",
    "        H = K.transpose(C-K.transpose(x))\n",
    "        return K.exp( -self.betas * K.sum(H**2, axis=1))\n",
    "        \n",
    "        #C = self.centers[np.newaxis, :, :]\n",
    "        #X = x[:, np.newaxis, :]\n",
    "\n",
    "        #diffnorm = K.sum((C-X)**2, axis=-1)\n",
    "        #ret = K.exp( - self.betas * diffnorm)\n",
    "        #return ret \n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        # have to define get_config to be able to use model_from_json\n",
    "        config = {\n",
    "            'output_dim': self.output_dim\n",
    "        }\n",
    "        base_config = super(RBFLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4e4e17cb0bc51fbf3371fbd830ef03e5b7b92b3f"
   },
   "source": [
    "# The model\n",
    "This method encapsulate the model, user can put inputTrainset, inputTestset, then column to drop, number of nodes in the hidden layer, epochs, batch size, is RBF (or else MLP), and also validation split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a703f2d50a251d14010e9571a3885f6a0c78672f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def executeModel(inputTrainset, inputTestset, columnsToDrop, numOfNodes=100, epochs=100, batch_size = None, verbose=True, isRBF=False, validationSplit=0):\n",
    "    print('==============================================================================')\n",
    "    print ('Delete columns: ')\n",
    "    print (columnsToDrop)\n",
    "    print ('Num of ndoes: ' + str(numOfNodes))\n",
    "    print ('Epochs: ' + str(epochs))\n",
    "    print('==============================================================================')\n",
    "    trainset = inputTrainset\n",
    "    testset = inputTestset\n",
    "    #Remove columns\n",
    "    trainset = trainset.drop(columnsToDrop, axis = 1)\n",
    "    testset = testset.drop(columnsToDrop, axis=1)\n",
    "    #y_train, X_train\n",
    "    y_train = trainset['RUL'].values\n",
    "    X_train = trainset.drop('RUL', axis=1)\n",
    "    #Converting to array\n",
    "    X_train = X_train.values\n",
    "\n",
    "    #y_test, X_test\n",
    "    y_test0 = testset['RUL']\n",
    "    y_test = y_test0.values\n",
    "    X_test = testset.drop('RUL', axis=1)\n",
    "    #Converting to array\n",
    "    X_test = X_test.values\n",
    "    # Feature Scaling\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    # Building the model\n",
    "    import keras\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.optimizers import RMSprop\n",
    "\n",
    "    model = Sequential()\n",
    "    layer1 = Dense(units=numOfNodes, activation='relu', input_dim = len(X_train[0]))\n",
    "    layer2 = Dense(units=1, activation='relu')\n",
    "    optimizer = 'adam'\n",
    "    if(isRBF):\n",
    "        layer1 = RBFLayer(10,\n",
    "                        initializer=InitCentersRandom(X_train), \n",
    "                        betas=2.0,\n",
    "                        input_shape=(len(X_train[0]),))\n",
    "        layer2 = Dense(units=1)\n",
    "        optimizer = RMSprop()\n",
    "    model.add(layer1)\n",
    "    model.add(layer2)\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\n",
    "\n",
    "    #Train the model\n",
    "    history=None\n",
    "    if(validationSplit==0):\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    else:\n",
    "        history = model.fit(X_train, y_train, validation_split=validationSplit, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    #Predict\n",
    "    y_pred_model = model.predict(X_test)\n",
    "    print('THE MODEL TRAIN SCORE IS: ' +str(history.history['loss'][-1]) + ', TEST SCORE IS: ' +str(calculateScore(y_pred_model, y_test)))\n",
    "    return (y_pred_model, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e5f23de0a7f198a1b77cc8e57d221005269c7e79"
   },
   "source": [
    "# Calculate score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1590d601f42b0b6e3abebd8bb383a27c9e32a0e1"
   },
   "source": [
    "This method is used to calculate the mse of the predicted RUL vs actual RULs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "61a7507b073afa1468c0ce43d3fab8c6147c14d7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "def calculateScore(y_pred, y_test):\n",
    "    y_pred  = list(map(lambda x: x[0], y_pred))\n",
    "    return mean_squared_error(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b972d884820228ea09bf9365750fec44c1b37dc"
   },
   "source": [
    "This section contains some pre-configurations (options) for building the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f3681ad067f3dfc404e947f1f7c0e04dbda11492",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "deleteCols = ['Unnamed: 0', 'unit']\n",
    "clsCol = ['cls']\n",
    "modeCols = ['mode1', 'mode2', 'mode3', 'mode4', 'mode5', 'mode6']\n",
    "featureCols = ['feature2', 'feature3', 'feature4', 'feature5', 'feature9', 'feature10', 'feature11', 'feature13', 'feature14', 'feature15', 'feature16', 'feature17', 'feature19', 'feature20', 'feature21']\n",
    "featureCols1 = ['feature1', 'feature2', 'feature3', 'feature4', 'feature7', 'feature10', 'feature11', 'feature12', 'feature14', 'feature15', 'feature16', 'feature17', 'feature18', 'feature19', 'feature20', 'feature21']\n",
    "cycleCol = ['cycle']\n",
    "settingCols = ['setting1', 'setting2', 'setting3']\n",
    "#The test RUL => for trainset or trainset1 are the same so just do for one\n",
    "y_test0 = testset0['RUL']\n",
    "y_test = y_test0.values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "21293278d7571d9e4fcaa4c6c7599f1a3953eceb"
   },
   "source": [
    "These are 30 the MLPs models with different configuration, un-comment them (recommended in a group of every 5 models, otherwise it would take a long time to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "5e37e036693ee6a4314f04d9eb9317426a7d344d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 100 EPOCHS')\n",
    "# y_pred_mod1, history1 = executeModel(trainset0, testset0, deleteCols, 100, 100, None, False, False)\n",
    "# y_pred_mod2, history2 = executeModel(trainset0, testset0, deleteCols+clsCol, 100, 100, None, False, False)\n",
    "# y_pred_mod3, history3 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 100, None, False, False)\n",
    "# y_pred_mod4, history4 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol, 100, 100, None, False, False)\n",
    "# y_pred_mod5, history5 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 100,None, False, False)\n",
    "\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 200 EPOCHS')\n",
    "# y_pred_mod6, history6 = executeModel(trainset0, testset0, deleteCols, 100, 200, None, False, False)\n",
    "# y_pred_mod7, history7 = executeModel(trainset0, testset0, deleteCols+clsCol, 100, 200, None, False, False)\n",
    "# y_pred_mod8, history8 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 200, None, False, False)\n",
    "# y_pred_mod9, history9 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol, 100, 200, None, False, False)\n",
    "# y_pred_mod10, history10= executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 200,None, False, False)\n",
    "\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 300 EPOCHS')\n",
    "# y_pred_mod11, history11 = executeModel(trainset0, testset0, deleteCols, 100, 300, None, False, False)\n",
    "# y_pred_mod12, history12 = executeModel(trainset0, testset0, deleteCols+clsCol, 100, 300, None, False, False)\n",
    "# y_pred_mod13, history13 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 300, None, False, False)\n",
    "# y_pred_mod14, history14 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol, 100, 300, None, False, False)\n",
    "# y_pred_mod15, history15 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 300, None, False, False)\n",
    "\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 100 EPOCHS, NON TRAIN DATA NORMALIZED BY CLASSES')\n",
    "# y_pred_mod16, history16 = executeModel(trainset1, testset1, deleteCols, 100, 100, None, False, False)\n",
    "# y_pred_mod17, history17 = executeModel(trainset1, testset1, deleteCols+clsCol, 100, 100, None, False, False)\n",
    "# y_pred_mod18, history18 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols, 100, 100, None, False, False)\n",
    "# y_pred_mod19, history19 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol, 100, 100, None, False, False)\n",
    "# y_pred_mod20, history20 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 100,None, False, False)\n",
    "\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 200 EPOCHS, NON TRAIN DATA NORMALIZED BY CLASSES')\n",
    "# y_pred_mod21, history21 = executeModel(trainset1, testset1, deleteCols, 100, 200, None, False, False)\n",
    "# y_pred_mod22, history22 = executeModel(trainset1, testset1, deleteCols+clsCol, 100, 200, None, False, False)\n",
    "# y_pred_mod23, history23 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols, 100, 200, None, False, False)\n",
    "# y_pred_mod24, history24 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol, 100, 200, None, False, False)\n",
    "# y_pred_mod25, history25 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 200, None, False, False)\n",
    "\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 300 EPOCHS, NON TRAIN DATA NORMALIZED BY CLASSES')\n",
    "# y_pred_mod26, history26 = executeModel(trainset1, testset1, deleteCols, 100, 300, None, False,False)\n",
    "# y_pred_mod27, history27 = executeModel(trainset1, testset1, deleteCols+clsCol, 100, 300, None, False, False)\n",
    "# y_pred_mod28, history28 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols, 100, 300, None, False, False)\n",
    "# y_pred_mod29, history29 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol, 100, 300, None, False, False)\n",
    "# y_pred_mod30, history30 = executeModel(trainset1, testset1, deleteCols+clsCol+modeCols+cycleCol+settingCols, 100, 300, None, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dd2e0abdc3f254259b8ab416fe8f392f17eaebde"
   },
   "source": [
    "This section print the loss history of all the models (un-comment the models that you uncommented in previous step to plot its learning history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cca506bdac4dc39b66200b3fe0f7b8af57d5344",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotLossHistory(history1)\n",
    "# plotLossHistory(history2)\n",
    "# plotLossHistory(history3)\n",
    "# plotLossHistory(history4)\n",
    "# plotLossHistory(history5)\n",
    "# plotLossHistory(history6)\n",
    "# plotLossHistory(history7)\n",
    "# plotLossHistory(history8)\n",
    "# plotLossHistory(history9)\n",
    "# plotLossHistory(history10)\n",
    "# plotLossHistory(history11)\n",
    "# plotLossHistory(history12)\n",
    "# plotLossHistory(history13)\n",
    "# plotLossHistory(history14)\n",
    "# plotLossHistory(history15)\n",
    "# plotLossHistory(history16)\n",
    "# plotLossHistory(history17)\n",
    "# plotLossHistory(history18)\n",
    "# plotLossHistory(history19)\n",
    "# plotLossHistory(history20)\n",
    "# plotLossHistory(history21)\n",
    "# plotLossHistory(history22)\n",
    "# plotLossHistory(history23)\n",
    "# plotLossHistory(history24)\n",
    "# plotLossHistory(history25)\n",
    "# plotLossHistory(history26)\n",
    "# plotLossHistory(history27)\n",
    "# plotLossHistory(history28)\n",
    "# plotLossHistory(history29)\n",
    "# plotLossHistory(history30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bab587a4fde9e08ffe0d1e818c3b57d34aa0440c"
   },
   "source": [
    "This section plots the predicted results vs the actual RULs for each model trained in previous steps (again uncomment corresponding models learned in previous steps to plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "752e33b9387890f25c9c646c389f8f1aae7ef952",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotUnitLines(y_pred_mod1, 1, 20, ncols=4, title='Model 1', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod2, 1, 20, ncols=4, title='Model 2', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod3, 1, 20, ncols=4, title='Model 3', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod4, 1, 20, ncols=4, title='Model 4', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod5, 1, 20, ncols=4, title='Model 5', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod6, 1, 20, ncols=4, title='Model 6', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod7, 1, 20, ncols=4, title='Model 7', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod8, 1, 20, ncols=4, title='Model 8', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod9, 1, 20, ncols=4, title='Model 9', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod10, 1, 20, ncols=4, title='Model 10', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod11, 1, 20, ncols=4, title='Model 11', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod12, 1, 20, ncols=4, title='Model 12', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod13, 1, 20, ncols=4, title='Model 13', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod14, 1, 20, ncols=4, title='Model 14', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod15, 1, 20, ncols=4, title='Model 15', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod16, 1, 20, ncols=4, title='Model 16', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod17, 1, 20, ncols=4, title='Model 17', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod18, 1, 20, ncols=4, title='Model 18', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod19, 1, 20, ncols=4, title='Model 19', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod20, 1, 20, ncols=4, title='Model 20', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod21, 1, 20, ncols=4, title='Model 21', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod22, 1, 20, ncols=4, title='Model 22', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod23, 1, 20, ncols=4, title='Model 23', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod24, 1, 20, ncols=4, title='Model 24', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod25, 1, 20, ncols=4, title='Model 25', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod26, 1, 20, ncols=4, title='Model 26', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod27, 1, 20, ncols=4, title='Model 27', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod28, 1, 20, ncols=4, title='Model 28', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod29, 1, 20, ncols=4, title='Model 29', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod30, 1, 20, ncols=4, title='Model 30', figsize=[15, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dbb22923fa6c33228856b57573894bf35dbde0db"
   },
   "source": [
    "This section contains methods with several feature selections (selecting some sensors using PCA or so), uncomment them to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da62a879b1b183b9fd1672c1786ed094546234df",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 100 EPOCHS, WITH FEATURE SELECTION 1')\n",
    "# y_pred_mod31, history31 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+featureCols, 100, 100, None, False, False)\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 200 EPOCHS, WITH FEATURE SELECTION 1')\n",
    "# y_pred_mod32, history32 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+featureCols, 100, 200, None, False, False)\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 100 EPOCHS, WITH FEATURE SELECTION 2')\n",
    "# y_pred_mod33, history33 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+featureCols1, 100, 100, None, False, False)\n",
    "# print('MODEL: 1 HIDDEN LAYER, 100 NODES, 200 EPOCHS, WITH FEATURE SELECTION 2')\n",
    "# y_pred_mod34, history34 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols+featureCols1, 100, 200, None, False, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fed39ce7145d3f20444047eb6222e65a6f9f2f8f"
   },
   "source": [
    "This section plot the training history of the models with feature selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "879f404842371d4fd20babb78d264afdf3ded568",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotLossHistory(history31)\n",
    "# plotLossHistory(history32)\n",
    "# plotLossHistory(history33)\n",
    "# plotLossHistory(history34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d7dc6d1c08514c198afdb17cb7c14e5272974911"
   },
   "source": [
    "This section plots the predicted results vs the actual RULs of the models with feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "32a519e7561ceb83b44523711d777eae2a4f91bc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotUnitLines(y_pred_mod31, 1, 20, ncols=4, title='Model 31', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod32, 1, 20, ncols=4, title='Model 32', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod33, 1, 20, ncols=4, title='Model 33', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred_mod34, 1, 20, ncols=4, title='Model 34', figsize=[15, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "86f19914631a49a1af82d1a1901c626c7d9f4595"
   },
   "source": [
    "# Combining models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "72a71abc48c5237287a637ee7a6a03eda369a2b2"
   },
   "source": [
    "This section tries to combine several models together to see the overall performance (like MLPs 1 hidden layer, 100 nodes + RBFs 1 hidden layer, 15 nodes + MLPs 1 hidden layer, 75 nodes with different number of epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c9fdb10b00d30ac6890755fbb5fe78e8db42154d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred35, history35 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 100, None, False, True)\n",
    "# y_pred36, history36 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 200, None, False, True)\n",
    "# y_pred37, history37 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 300, None, False, True)\n",
    "# y_pred44, history44 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 40, None, False, True)\n",
    "# y_pred47, history47 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 50, None, False, True)\n",
    "\n",
    "# y_pred38, history38 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 100, None, False, False)\n",
    "# y_pred39, history39 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 200, None, False, False)\n",
    "# y_pred40, history40 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 300, None, False, False)\n",
    "# y_pred45, history45 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 40, None, False, False)\n",
    "# y_pred48, history48 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 50, None, False, True)\n",
    "\n",
    "# y_pred41, history41 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 75, 100, None, False, False)\n",
    "# y_pred42, history42 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 75, 200, None, False, False)\n",
    "# y_pred43, history43 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 75, 300, None, False, False)\n",
    "# y_pred46, history46 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 75, 40, None, False, False)\n",
    "# y_pred49, history49 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 50, None, False, True)\n",
    "#ensemble\n",
    "# y_pred353841 = (y_pred35 + y_pred38 + y_pred41)/3\n",
    "# y_pred363942 = (y_pred36 + y_pred39 + y_pred42)/3\n",
    "# y_pred374043 = (y_pred37 + y_pred40 + y_pred43)/3\n",
    "# y_pred444546 = (y_pred44 + y_pred45 + y_pred46)/3\n",
    "# y_pred474849 = (y_pred47 + y_pred48 + y_pred49)/3\n",
    "#calculate score\n",
    "# print(\"Score 353841: \" + str(calculateScore(y_pred353841, y_test)))\n",
    "# print(\"Score 363942: \" + str(calculateScore(y_pred363942, y_test)))\n",
    "# print(\"Score 374043: \" + str(calculateScore(y_pred374043, y_test)))\n",
    "# print(\"Score 444546: \" + str(calculateScore(y_pred444546, y_test)))\n",
    "# print(\"Score 474849: \" + str(calculateScore(y_pred474849, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "070584a0d2db4840bacc7c75f08fae32b4d263e4"
   },
   "source": [
    "Plot the learning history of each separate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4f9abfa3160d4f9624776824c448af311c089054",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotLossHistory(history35)\n",
    "# plotLossHistory(history36)\n",
    "# plotLossHistory(history37)\n",
    "# plotLossHistory(history44)\n",
    "# plotLossHistory(history47)\n",
    "# plotLossHistory(history38)\n",
    "# plotLossHistory(history39)\n",
    "# plotLossHistory(history40)\n",
    "# plotLossHistory(history45)\n",
    "# plotLossHistory(history48)\n",
    "# plotLossHistory(history41)\n",
    "# plotLossHistory(history42)\n",
    "# plotLossHistory(history43)\n",
    "# plotLossHistory(history46)\n",
    "# plotLossHistory(history49)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "35908faaa689da606812f379cbc7e21ad3d894c5"
   },
   "source": [
    "Plot the predicted results of each separate model and the combined results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c10434ea636f857a8319e7c85cf99a2db39b83fc",
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plotUnitLines(y_pred35, 1, 20, ncols=4, title='Model 35', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred36, 1, 20, ncols=4, title='Model 36', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred37, 1, 20, ncols=4, title='Model 37', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred38, 1, 20, ncols=4, title='Model 38', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred39, 1, 20, ncols=4, title='Model 39', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred40, 1, 20, ncols=4, title='Model 40', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred41, 1, 20, ncols=4, title='Model 41', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred42, 1, 20, ncols=4, title='Model 42', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred43, 1, 20, ncols=4, title='Model 43', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred44, 1, 20, ncols=4, title='Model 44', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred45, 1, 20, ncols=4, title='Model 45', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred46, 1, 20, ncols=4, title='Model 46', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred47, 1, 20, ncols=4, title='Model 47', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred48, 1, 20, ncols=4, title='Model 48', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred49, 1, 20, ncols=4, title='Model 49', figsize=[15, 15])\n",
    "\n",
    "# plotUnitLines(y_pred353841, 1, 20, ncols=4, title='Model 353841', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred363942, 1, 20, ncols=4, title='Model 363942', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred374043, 1, 20, ncols=4, title='Model 374043', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred444546, 1, 20, ncols=4, title='Model 444', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred474849, 1, 20, ncols=4, title='Model 474849', figsize=[15, 15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "647904727b75f5a0c68914f01fddf90ee9d2bcd3"
   },
   "source": [
    "# Using validation to select better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "41be55ef3a2d734335238e11bcc438990224c277"
   },
   "source": [
    "This section we executes models with large number of epochs + adding validation split in order to find a good model ( un comment the models to test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6758671a74d89a2dbe04de5f76cc4aeb67126eec",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# y_pred50, history50 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 15, 300, None, False, True, 0.33)\n",
    "# y_pred51, history51 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 300, None, False, False, 0.33)\n",
    "#Try RBF with 100 nodes\n",
    "y_pred52, history52 = executeModel(trainset0, testset0, deleteCols+clsCol+modeCols, 100, 300, None, False, True, 0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "77432166638961e780812da30a6f28607ffb5dfa"
   },
   "source": [
    "Plot the train history (including of training mse and validating mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bdf040d7b8565a576a85afe5ccf8a9b6c2531292",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotTrainHistory(history50)\n",
    "# plotTrainHistory(history51)\n",
    "plotTrainHistory(history52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f419d1228ebf90efaf4651dd4b039f8143a69a30"
   },
   "source": [
    "Plot the predicted results for each unit vs its actual RUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "acfafc8c052d2c4a18d4636b149700c1f3673a19",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotUnitLines(y_pred50, 1, 20, ncols=4, title='Model 50', figsize=[15, 15])\n",
    "# plotUnitLines(y_pred51, 1, 20, ncols=4, title='Model 51', figsize=[15, 15])\n",
    "plotUnitLines(y_pred52, 1, 20, ncols=4, title='Model 52', figsize=[15, 15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bec912a5389b0076f2a17606fbbfae764cd297c2",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
